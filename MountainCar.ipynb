{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from common import (\n",
    "    Discretizer,\n",
    ")\n",
    "from observers import (\n",
    "    StateAnalysisLogger,\n",
    "    WindowMetricLogger,\n",
    ")\n",
    "from training import (\n",
    "    DiscreteQLearningTrainer,\n",
    "    DiscreteQLearningTrainingConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 1. Create environment\n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup Training Config\n",
    "epsilon = 0.2\n",
    "training_config = DiscreteQLearningTrainingConfig(\n",
    "    learning_rate=0.1,\n",
    "    discount=0.9,\n",
    "    episodes=2500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Discretize Space\n",
    "discretizer = Discretizer(env, [0.1, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add Observers\n",
    "mean_reward_logger = WindowMetricLogger(window_size=50, metric='reward')\n",
    "state_analysis = StateAnalysisLogger(env=env, discretizer=discretizer, frequency=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Put it all together\n",
    "model = DiscreteQLearningTrainer(\n",
    "    env=env, \n",
    "    discretizer=discretizer, \n",
    "    training_config=training_config,\n",
    "    epsilon=epsilon,\n",
    "    observers=[\n",
    "        mean_reward_logger,\n",
    "        state_analysis\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Window reward: -200.0\n",
      "Visitation Pct: 0.021052631578947368\n",
      "Epoch: 50 | Window reward: -200.0\n",
      "Epoch: 100 | Window reward: -200.0\n",
      "Visitation Pct: 0.28888888888888886\n",
      "Epoch: 150 | Window reward: -200.0\n",
      "Epoch: 200 | Window reward: -200.0\n",
      "Visitation Pct: 0.4070175438596491\n",
      "Epoch: 250 | Window reward: -200.0\n",
      "Epoch: 300 | Window reward: -200.0\n",
      "Visitation Pct: 0.4678362573099415\n",
      "Epoch: 350 | Window reward: -199.42\n",
      "Epoch: 400 | Window reward: -200.0\n",
      "Visitation Pct: 0.5497076023391813\n",
      "Epoch: 450 | Window reward: -200.0\n",
      "Epoch: 500 | Window reward: -200.0\n",
      "Visitation Pct: 0.5660818713450292\n",
      "Epoch: 550 | Window reward: -199.46\n",
      "Epoch: 600 | Window reward: -196.04\n",
      "Visitation Pct: 0.6035087719298246\n",
      "Epoch: 650 | Window reward: -197.36\n",
      "Epoch: 700 | Window reward: -195.6\n",
      "Visitation Pct: 0.6105263157894737\n",
      "Epoch: 750 | Window reward: -199.98\n",
      "Epoch: 800 | Window reward: -195.48\n",
      "Visitation Pct: 0.6175438596491228\n",
      "Epoch: 850 | Window reward: -199.78\n",
      "Epoch: 900 | Window reward: -195.72\n",
      "Visitation Pct: 0.6210526315789474\n",
      "Epoch: 950 | Window reward: -195.3\n",
      "Epoch: 1000 | Window reward: -199.16\n",
      "Visitation Pct: 0.6222222222222222\n",
      "Epoch: 1050 | Window reward: -198.94\n",
      "Epoch: 1100 | Window reward: -196.04\n",
      "Visitation Pct: 0.6222222222222222\n",
      "Epoch: 1150 | Window reward: -188.0\n",
      "Epoch: 1200 | Window reward: -197.84\n",
      "Visitation Pct: 0.6222222222222222\n",
      "Epoch: 1250 | Window reward: -192.58\n",
      "Epoch: 1300 | Window reward: -173.0\n",
      "Visitation Pct: 0.624561403508772\n",
      "Epoch: 1350 | Window reward: -190.94\n",
      "Epoch: 1400 | Window reward: -199.24\n",
      "Visitation Pct: 0.6269005847953216\n",
      "Epoch: 1450 | Window reward: -190.92\n",
      "Epoch: 1500 | Window reward: -186.9\n",
      "Visitation Pct: 0.6269005847953216\n",
      "Epoch: 1550 | Window reward: -191.7\n",
      "Epoch: 1600 | Window reward: -192.08\n",
      "Visitation Pct: 0.6304093567251462\n",
      "Epoch: 1650 | Window reward: -195.02\n",
      "Epoch: 1700 | Window reward: -185.24\n",
      "Visitation Pct: 0.6304093567251462\n",
      "Epoch: 1750 | Window reward: -194.94\n",
      "Epoch: 1800 | Window reward: -193.74\n",
      "Visitation Pct: 0.631578947368421\n",
      "Epoch: 1850 | Window reward: -177.5\n",
      "Epoch: 1900 | Window reward: -184.92\n",
      "Visitation Pct: 0.631578947368421\n",
      "Epoch: 1950 | Window reward: -186.6\n",
      "Epoch: 2000 | Window reward: -197.54\n",
      "Visitation Pct: 0.632748538011696\n",
      "Epoch: 2050 | Window reward: -188.84\n",
      "Epoch: 2100 | Window reward: -199.46\n",
      "Visitation Pct: 0.6350877192982456\n",
      "Epoch: 2150 | Window reward: -183.58\n",
      "Epoch: 2200 | Window reward: -190.28\n",
      "Visitation Pct: 0.6362573099415205\n",
      "Epoch: 2250 | Window reward: -192.04\n",
      "Epoch: 2300 | Window reward: -198.4\n",
      "Visitation Pct: 0.6362573099415205\n",
      "Epoch: 2350 | Window reward: -191.58\n",
      "Epoch: 2400 | Window reward: -199.5\n",
      "Visitation Pct: 0.6362573099415205\n",
      "Epoch: 2450 | Window reward: -176.12\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
